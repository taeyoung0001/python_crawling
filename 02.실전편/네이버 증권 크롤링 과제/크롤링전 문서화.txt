# 네이버 증권 뉴스 크롤링 전 스스로 문서화 해보기

목표 : 제목, 링크, 내용, 언론사, 날짜 크롤링해서 엑셀로 뿌리기

1. 제목, 링크, 내용, 언론사, 날짜 get으로 가져오기

2. 링크, 내용, 가공해야함 
  - 링크는 앞에 태그를 지워야 할듯 (해결)
  - 내용에는 내용만 나와야하는데 언론사와 날짜가 나오고 있음 (해결)
  - 링크에 프로토콜과 도메인 주소가 나오지 않는 현상 확인 (해결)
  


피드백 : 

1 .태그 구조를 잘 봐야함 
2. strip() 문법은 공백을 지워줌
3. 조건문을 사용해서 none에서 breack를 걸어줘야함 



# 아래 gpt로 실험삼아서 리팩토링 한 코드 입니다. 추후 확인 예정!! 
# gpt도움없이 이렇게 짜보고 싶어서 눈에라도 익히는 중!

- 함수 분리: 기능별로 분리하여 코드 가독성과 재사용성을 높임.
- 페이지 종료 조건 추가: .pgRR를 확인하여 마지막 페이지에서 자동 종료.
- 불필요한 중복 제거: BeautifulSoup 및 데이터 추가 로직 최적화.
- 사용자 정의 가능: 날짜와 출력 파일 이름을 쉽게 변경할 수 있도록 매개변수화.

import requests
from bs4 import BeautifulSoup
import pandas as pd


# 상수 정의
BASE_URL = "https://finance.naver.com/news/mainnews.naver"

# 뉴스 데이터 수집 함수
def fetch_news(date: str, max_pages: int = 9999) -> list:
    """특정 날짜의 뉴스 데이터를 수집"""
    data = []
    for page in range(1, max_pages + 1):
        # 페이지 요청 및 파싱
        response = requests.get(f"{BASE_URL}?date={date}&page={page}")
        soup = BeautifulSoup(response.text, 'html.parser')

        # 뉴스 항목 가져오기
        items = soup.select('.block1')
        if not items:  # 데이터가 없으면 종료
            break

        # 데이터 추출
        for item in items:
            try:
                title = item.select_one('.articleSubject > a').text
                link = 'https://finance.naver.com' + item.select_one('.articleSubject > a')['href']
                content = item.select_one('.articleSummary').text.strip()
                press = item.select_one('.press').text
                wdate = item.select_one('.wdate').text
                data.append([title, link, content, press, wdate])
            except AttributeError:
                # 일부 데이터 누락 시 건너뛰기
                continue

        # 마지막 페이지 확인
        if soup.select_one(".pgRR") is None:
            break

    return data


# 데이터 저장 함수
def save_to_excel(data: list, file_name: str):
    """데이터를 엑셀 파일로 저장"""
    df = pd.DataFrame(data, columns=['제목', '링크', '내용', '언론사', '날짜'])
    df.to_excel(file_name, index=False, encoding='utf-8-sig')
    print(f"엑셀 파일 저장 완료: {file_name}")


# 메인 실행
if __name__ == "__main__":
    # 수집할 날짜와 출력 파일 설정
    target_date = "2024-11-29"  # 수집할 뉴스 날짜
    output_file = "naver_result.xlsx"

    # 뉴스 데이터 수집 및 저장
    news_data = fetch_news(target_date)
    save_to_excel(news_data, output_file)

